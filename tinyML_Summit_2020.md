##OpenM1 Project Demo  
This [demonstration](https://tinymlsummit.org/abstracts/On_Device_AI_demo_abstract.pdf) is how to used OpenM1 to build [TensorFlow Lite for Microcontrollers](https://www.tensorflow.org/lite/microcontrollers) examples on the Windows10 operating system. About OpenM1 is an open-source experimental project that lets developers of TensorFlow Lite for Microcontrollers to easily create and build projects on Windows.  
Since [On-Device AI Co., Ltd.](https://on-device-ai.com/) is a technology service company, some customers want that they can easily use our released project's base on TensorFlow Lite for Microcontrollers and build them on Windows. Therefore, we created the OpenM1. It includes the GUI application, the [Miniconda](https://docs.conda.io/en/latest/miniconda.html) distribution for Python program development, and the [WSL](https://docs.microsoft.com/windows/wsl/) feature for source code building.  
The GUI application references the [OpenR8](https://www.openrobot.club/article/index?sn=10935) software concept and integrates the commands that need executing during the build process.  When building a project, not requirements are that customers have familiarity running commands in the Command Prompt on Windows.   
Miniconda is a free minimal installer for conda. It is a small, bootstrap version of Anaconda that includes only conda, Python, the packages they depend on, and a small number of other useful packages, including pip, zlib, and a few others. We "portable" Miniconda to run without installation and integrate into OpenM1. It provides a programming environment for Python coding of TensorFlow and TensorFlow Lite.  
WSL (Windows Subsystem for Linux) is an environment in Windows10 for running unmodified Linux binaries in a way similar to Linux Containers. Compile TensorFlow Lite for Microcontrollers examples or applications source code on Windows is not easy now. For example, the GCC toolchain of SparkFun Edge only supports macOS and Linux. So, OpenM1 uses Ubuntu on WSL for project building.  
  
